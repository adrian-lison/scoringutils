#' @title scoringutils
#'
#' @description
#' This package is designed to help with assessing the quality of predictions.
#' It provides a collection of proper scoring rules and metrics as well that
#' can be accessed independently or collectively through a higher-level wrapper
#' function.
#'
#' Predictions can be either probabilistic forecasts (generally predictive
#' samples generated by Markov Chain Monte Carlo procedures), quantile
#' forecasts or point forecasts. The true values can be either continuous,
#' integer, or binary.
#'
#' A collection of different metrics and scoring rules can be accessed through
#' the function [eval_forecasts()]. Given a data.frame of the
#' correct form the function will automatically figure out the type of
#' prediction and true values and return appropriate scoring metrics.
#'
#' The package also has a lot of default visualisation based on the output
#' created by [eval_forecasts()].
#'
#' - [score_table()]
#' - [correlation_plot()]
#' - [wis_components()]
#' - [range_plot()]
#' - [score_heatmap()]
#' - [plot_predictions()]
#' - [interval_coverage()]
#' - [quantile_coverage()]
#'
#' Alternatively, the following functions can be accessed directly:
#'
#' - [brier_score()]
#' - [pit()]
#' - [bias()]
#' - [quantile_bias()]
#' - [sharpness()]
#' - [crps()]
#' - [logs()]
#' - [dss()]
#' - [ae_median_sample()]
#'
#' Predictions can be evaluated in a lot of different formats. If you want to
#' convert from one format to the other, the following helper functions can
#' do that for you:
#'
#' - [sample_to_range_long()]
#' - [sample_to_quantile()]
#' - [quantile_to_range_long()]
#' - [range_long_to_quantile()]
#'
#' @docType package
#' @name scoringutils

NULL
